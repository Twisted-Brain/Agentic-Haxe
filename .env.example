# Environment Configuration for Haxe LLM Gateway PoC
# Copy this file to .env and fill in your values

# OpenRouter API Configuration
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your-api-key-here

# LLM Model Selection
# Available models:
# - openai/gpt-3.5-turbo (default, fast and cost-effective)
# - openai/gpt-4 (more capable, slower and more expensive)
# - openai/gpt-4-turbo (latest GPT-4 variant)
# - anthropic/claude-3-haiku (fast Claude model)
# - anthropic/claude-3-sonnet (balanced Claude model)
# - anthropic/claude-3-opus (most capable Claude model)
# - meta-llama/llama-2-70b-chat (open source alternative)
# - mistralai/mixtral-8x7b-instruct (efficient open source model)
LLM_MODEL=openai/gpt-3.5-turbo

# Gateway Configuration
# Timeout for API requests (in milliseconds)
API_TIMEOUT=30000

# Maximum number of retries for failed requests
MAX_RETRIES=3

# Development Configuration
# Port for frontend development server
FRONTEND_PORT=8000

# Port for backend gateway (if implementing HTTP server)
BACKEND_PORT=8080

# Enable debug logging
DEBUG=false

# Demo Mode
# Set to true to use simulated responses instead of real API calls
DEMO_MODE=false